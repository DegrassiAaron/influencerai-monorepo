Executive summary

Monorepo TS (Next.js dashboard, NestJS API, worker BullMQ) + n8n locale.

Postgres + Redis + MinIO locali via Docker.

LoRA training con kohya_ss (CLI) + ComfyUI per pipeline img/video + FFmpeg per packaging.

OpenRouter solo per testo (caption/script/hashtag/brief) con cap costi e stima token.

Autopost gestito via connettori n8n (Meta/YouTube/TikTok dove possibile) con tunnel (cloudflared) per webhooks dal locale.

[Unverified] Alcune piattaforme (in particolare TikTok) limitano l’auto-publishing via API; dove non consentito userai export + reminder.

Stack decision

Frontend: Next.js (App Router), Tailwind, shadcn/ui, TanStack Query.

Backend: NestJS (Fastify) + Prisma su Postgres, Zod per DTO, BullMQ su Redis.

Storage: MinIO (S3-compat) locale; cartelle “hot” su SSD per dataset/LoRA.

Orchestrazione: n8n locale (Docker) → chiama API interne, lancia job (HTTP/queues), riceve webhooks.

AI: OpenRouter (testo); immagini da Leonardo (manuale), video/immagini “on-prem” con ComfyUI; kohya_ss per addestrare LoRA a partire dai tuoi set.

Struttura repo (Turborepo)
influencerai/
  apps/
    web/            # Next.js dashboard (planner, assets, runbook)
    api/            # NestJS: auth, tenants, influencers, datasets, jobs
    worker/         # BullMQ consumers (text→img→video→post)
    n8n/            # mount dei workflow JSON/YAML e env
  packages/
    core-schemas/   # zod: JobSpec, ContentPlan, DatasetSpec, LoRAConfig
    sdk/            # client fetcher, hooks, api-typing
    prompts/        # template LLM (system/user), preset qualità
  data/
    datasets/       # immagini per LoRA (+captions)
    loras/          # output .safetensors
    outputs/        # immagini/video generati
  infra/
    docker-compose.yml
    cloudflared/    # opzionale: tunnel per webhooks
  .env

docker-compose.yml (locale)
version: "3.8"
services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_USER: postgres
      POSTGRES_DB: influencerai
    volumes: [pg:/var/lib/postgresql/data]
    ports: ["5432:5432"]

  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio12345
    volumes: [minio:/data]
    ports: ["9000:9000", "9001:9001"]

  n8n:
    image: n8nio/n8n:latest
    environment:
      - N8N_HOST=localhost
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:5678/
      - N8N_SECURE_COOKIE=false
    ports: ["5678:5678"]
    volumes:
      - ./apps/n8n:/home/node/.n8n

  api:
    build: ./apps/api
    env_file: [.env]
    depends_on: [postgres, redis, minio]
    ports: ["3001:3001"]

  worker:
    build: ./apps/worker
    env_file: [.env]
    depends_on: [redis, api]
    deploy: { resources: { reservations: { devices: [ { capabilities: [gpu] } ] } } } # opzionale se usi GPU in worker

  web:
    build: ./apps/web
    env_file: [.env]
    depends_on: [api]
    ports: ["3000:3000"]

volumes:
  pg:
  minio:


.env (chiavi principali)

DATABASE_URL=postgresql://postgres:postgres@postgres:5432/influencerai
REDIS_URL=redis://redis:6379
S3_ENDPOINT=http://minio:9000
S3_KEY=minio
S3_SECRET=minio12345
S3_BUCKET=assets
OPENROUTER_API_KEY=...

Schema dati (Prisma – estratto minimo)
model Tenant {
  id        String  @id @default(cuid())
  name      String
  influencers Influencer[]
  createdAt DateTime @default(now())
}

model Influencer {
  id        String @id @default(cuid())
  tenantId  String
  name      String
  persona   Json        // voice, style refs, dos/donts
  datasetId String?     // dataset di training attivo
  Tenant    Tenant  @relation(fields: [tenantId], references: [id])
}

model Dataset {
  id        String @id @default(cuid())
  tenantId  String
  kind      String   // "lora"
  path      String   // data/datasets/xyz
  meta      Json
  status    String   // ready|training|failed
  createdAt DateTime @default(now())
}

model Job {
  id        String  @id @default(cuid())
  type      String  // plan|caption|lora-train|img|video|autopost
  status    String  // queued|running|done|failed
  payload   Json
  result    Json?
  costTok   Int?    // token stimati/consumati (OpenRouter)
  startedAt DateTime?
  finishedAt DateTime?
}

model Asset {
  id       String @id @default(cuid())
  jobId    String
  type     String // caption|image|video
  url      String // s3://assets/...  (MinIO)
  meta     Json
  Job      Job    @relation(fields: [jobId], references: [id])
}

Workflow n8n (locale)

Webhook principali

POST /plan/generate → chiama api per creare ContentPlan (OpenRouter: brief, caption/hashtag themes).

POST /lora/train → crea job lora-train con kohya_ss (CLI) e dataset path.

POST /content/run → sequenza: caption → img (ComfyUI o manuale Leonardo) → video (ComfyUI graph) → autopost.

POST /publish → invia verso connettori social (vedi sotto).

POST /webhook/comfyui → ricezione completamento render (se usi HTTP node in ComfyUI).

Nodes tipici

HTTP Request (API interne)

Execute Command (lancia kohya_ss, python comfy.py -g graph.json -o ...)

S3 (MinIO) upload/download

Function (mapping payload)

If/Switch per preset qualità e percorsi manuali/automatici

Wait/Retry per polling stato job

Tunnels per webhooks

Usa cloudflared per esporre i webhooks esternamente: cloudflared tunnel --url http://localhost:5678

[Inference] È stabile e gratuito; alternativa: ngrok free (limiti di sessione).

Pipeline LoRA (locale)

Dataset: in data/datasets/<nome>/{images,captions} — puoi inserire qui anche le immagini curate da Leonardo.ai (manuale).

Captioning (opzionale): BLIP/CLIP interrogator (script locale) per auto-caption; revisione rapida.

Train: kohya_ss (SDXL o modelli compatibili) con config salvato per replicabilità.

Esempio comando:

accelerate launch kohya_ss/train_network.py \
  --network_module=networks.lora --pretrained_model_name_or_path="base.safetensors" \
  --train_data_dir="data/datasets/NAME/images" --output_dir="data/loras/NAME" \
  --resolution=1024,1024 --network_dim=16 --network_alpha=16 \
  --learning_rate=1e-4 --max_train_steps=800 --caption_extension=".txt"


Registry: salva .safetensors in data/loras/NAME + meta.json (seed, steps, loss).

Uso: ComfyUI graph che carica base model + LoRA e genera immagini coerenti.

Pipeline video (locale)

ComfyUI con graph AnimateDiff / SVD / VideoCrafter-like (a seconda della GPU).

FFmpeg: normalizzazione aspect (9:16, 1:1, 16:9), burn-in sottotitoli, loudness.

n8n gestisce batch: split testo → shotlist → img keyframes → motion gen → stitching.

Autopost (n8n)

Instagram/Facebook: [Unverified] via Graph API (account Business/Creator, permessi, media container → publish).

YouTube Shorts: upload API (quota/limiti, titolo/descrizione/tag, privacy).

TikTok: [Unverified] API pubblicazione limitata/partner; in caso di blocco → export + reminder + apertura app via Deep Link (desktop).

Scheduler: n8n cron + coda autopost; idempotenza con external_id.

Controllo costi OpenRouter

Stima token ex-ante: funzione TS (conteggio prompt+output atteso) → mostrare costo stimato in UI e salvarlo in Job.costTok.

Cap mensile: variabile per tenant; al superamento → downgrade preset (“Eco”) o blocco soft.

Cache: per “ideation” simili, salva prompt→risposta (hash) per riuso.

Comandi iniziali (scaffold)
# Monorepo
pnpm dlx create-turbo@latest influencerai
cd influencerai

# Apps
pnpm dlx create-next-app@latest apps/web --ts --eslint --app
pnpm dlx @nestjs/cli new apps/api
mkdir -p apps/worker packages/{core-schemas,sdk,prompts} infra data/{datasets,loras,outputs}

# API deps
cd apps/api
pnpm add @nestjs/config @nestjs/swagger @nestjs/platform-fastify zod
pnpm add prisma @prisma/client
pnpm dlx prisma init

# Worker deps
cd ../../apps/worker
pnpm init -y
pnpm add bullmq ioredis zod undici p-queue

# Root dev
cd ../..
docker compose up -d
pnpm -w install

Endpoints iniziali (NestJS – idea)

POST /jobs/plan → crea job LLM (brief/caption)

POST /jobs/lora-train → lancia training (enqueue)

POST /jobs/image → enqueue ComfyUI render (o manual)

POST /jobs/video → enqueue video graph

POST /jobs/autopost → enqueue publish

GET /jobs/:id → stato + risultati

PUT /datasets/:id → aggiorna meta/stato

I consumer in apps/worker leggono da code plan, lora-train, image, video, autopost, aggiornano Job.status e caricano asset su MinIO.

UI (Next.js)

Planner (calendar + kanban) per brand/influencer.

Dataset Manager (drag&drop immagini, captions, validazione).

LoRA Trainer (config preset + avvio + dashboard training).

Asset Manager (anteprime img/video, variant generator).

Publishing (preview, check policy, schedule).

Perché potrebbe non funzionare / failure modes

GPU saturata / VRAM insufficiente → riduci batch/resolution, usa “Eco graph”; coda con priorità; profiling ComfyUI.

API social cambiano → astrazione connettori in n8n + fallback export.

Qualità incoerente tra influencer → versiona StylePack (prompt, neg, seeds, CFG, LoRA weights) per brand.

Costi OpenRouter imprevisti → cap “hard”, cache risultati, “dry-run” token estimate prima di lanciare batch.

I/O locale lento → SSD NVMe per data/ e parallelismo moderato (P-queue).

Reasoning summary

Con budget solo per OpenRouter e resto on-prem, la leva è massimizzare pipeline locali (LoRA/ComfyUI/FFmpeg) e usare n8n come colla.

TS end-to-end semplifica DevX; n8n isola le integrazioni e ti dà UI per orchestrare.

Ho fornito compose, schema, folder, workflow e comandi per iniziare subito con MVP riproducibile.

Prossimi passi concreti

Crea la repo influencerai e incolla compose + .env.

Scaffold Next/Nest/Worker con i comandi sopra.

Importa in n8n i 3 webhook (/plan/generate, /lora/train, /content/run) e collegali a api/worker.

Installa ComfyUI e kohya_ss; prepara un graph base e un config LoRA.

Test end-to-end: plan → caption → img (manuale o auto) → video → export → autopost (IG/YT) o fallback export.